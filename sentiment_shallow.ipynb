{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import necessary depencencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.0.0/en_core_web_sm-2.0.0.tar.gz\n",
      "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.0.0/en_core_web_sm-2.0.0.tar.gz (37.4MB)\n",
      "\u001b[K    100% |################################| 37.4MB 12.3MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied (use --upgrade to upgrade): en-core-web-sm==2.0.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.0.0/en_core_web_sm-2.0.0.tar.gz in /home/tie-server/anaconda3/lib/python3.6/site-packages\n",
      "\n",
      "\u001b[93m    Linking successful\u001b[0m\n",
      "    /home/tie-server/anaconda3/lib/python3.6/site-packages/en_core_web_sm\n",
      "    --> /home/tie-server/anaconda3/lib/python3.6/site-packages/spacy/data/en\n",
      "\n",
      "    You can now load the model via spacy.load('en')\n",
      "\n",
      "[nltk_data] Downloading package sentiwordnet to /home/tie-\n",
      "[nltk_data]     server/nltk_data...\n",
      "[nltk_data]   Package sentiwordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/tie-\n",
      "[nltk_data]     server/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/tie-server/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt to /home/tie-server/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/tie-\n",
      "[nltk_data]     server/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to /home/tie-\n",
      "[nltk_data]     server/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import model_evaluation_utils as meu\n",
    "import pickle\n",
    "import random\n",
    "import os\n",
    "import text_normalizer as tn\n",
    "import nltk\n",
    "!python -m spacy download en\n",
    "\n",
    "nltk.download('sentiwordnet')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "np.set_printoptions(precision=2, linewidth=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Change path to dataset here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "basedir = os.path.join(os.sep, \"media\", \"tie-server\", \"DATA\", \"Jens\", \"Crunchbase\")\n",
    "#tempdir = os.getcwd()\n",
    "tempdir = basedir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (os.path.join(tempdir, 'temp_data', 'sample_labelled_df'), 'rb') as fp:\n",
    "    sample_labelled_df = pickle.load(fp)\n",
    "\n",
    "test_articles = np.array(sample_labelled_df['paragraphs'])\n",
    "test_sentiments = np.array(sample_labelled_df['label'])\n",
    "\n",
    "# extract data for model evaluation\n",
    "random.seed(13)\n",
    "sample_article_ids = random.sample(list(range(0,len(sample_labelled_df)-1)), 3)\n",
    "\n",
    "# normalize dataset\n",
    "norm_test_articles = tn.normalize_corpus(test_articles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Sentiment Analysis with AFINN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from afinn import Afinn\n",
    "\n",
    "afn = Afinn(emoticons=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict sentiment for sample articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article:  alexandria, va: united states patent and trademark office has received an application no. 20170281686 for us patent, published on october 5, 2017, by stembiosys, inc. (texas), titled as \"bone marrow stromal cell derived extracellular matrix protein extract and uses thereof\"  for the registration of patent.\n",
      "\n",
      " stembiosys, inc. (texas) applies for us patent titled as \"bone marrow stromal cell derived extracellular matrix protein extract and uses thereof\"\n",
      "Actual Sentiment: neutral\n",
      "Predicted Sentiment polarity: 0.0\n",
      "------------------------------------------------------------\n",
      "Article: fashion and apparel, a $110-130 billion market, offers 30-40% margins but it is crowded with the likes of the flipkart-jabong-myntra combine, amazon and more than 800 other players such as limeroad and voonik jostling for space. snapdeal will spend $100 million to build this category, says bahl.\\x93to build any of these we could even look at acquiring capabilities,\\x93 says bahl. the acquisition in may 2016 of targetingmantra, a predictive marketing tech firm that helps make recommendations, might help here.\n",
      "Actual Sentiment: neutral\n",
      "Predicted Sentiment polarity: 7.0\n",
      "------------------------------------------------------------\n",
      "Article: medallia, the sillicon valley based company that supplies tools for real time measuring of customers experience with corporations, has local operations since 2011. president cristian rapagna says most of its clients are large corporations that need to keep in touch with customers to assess the acceptance of products and services. the goal is to gather data to improve the customers experience, as fulfilled customers tend to increase expenditures, contrary to the ones that have had a poor experience. medallia is the sole company to offer these tools and services, while market feedback services are not considered competitors, the company, with 650 employees, collects information from social networks and the internet assessing customers satisfaction. the local branch also develop tools related to the business of its parent in the us.\n",
      "Actual Sentiment: neutral\n",
      "Predicted Sentiment polarity: 4.0\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for article, sentiment in zip(test_articles[sample_article_ids], test_sentiments[sample_article_ids]):\n",
    "    print('Article:', article)\n",
    "    print('Actual Sentiment:', sentiment)\n",
    "    print('Predicted Sentiment polarity:', afn.score(article))\n",
    "    print('-'*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict sentiment for test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_polarity = [afn.score(article) for article in test_articles]\n",
    "predicted_sentiments = ['positive' if score >= 1.0 else 'negative' for score in sentiment_polarity]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance metrics:\n",
      "------------------------------\n",
      "Accuracy: 0.0612\n",
      "Precision: 0.0039\n",
      "Recall: 0.0612\n",
      "F1 Score: 0.0073\n",
      "\n",
      "Model Classification report:\n",
      "------------------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   positive       0.07      1.00      0.13         5\n",
      "   negative       0.04      1.00      0.08         1\n",
      "\n",
      "avg / total       0.06      1.00      0.12         6\n",
      "\n",
      "\n",
      "Prediction Confusion Matrix:\n",
      "------------------------------\n",
      "                 Predicted:         \n",
      "                   positive negative\n",
      "Actual: positive          5        0\n",
      "        negative          0        1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tie-server/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/tie-server/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "meu.display_model_performance_metrics(true_labels=test_sentiments, predicted_labels=predicted_sentiments, \n",
    "                                  classes=['positive', 'negative'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis with SentiWordNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive Polarity Score: 0.875\n",
      "Negative Polarity Score: 0.125\n",
      "Objective Score: 0.0\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import sentiwordnet as swn\n",
    "\n",
    "awesome = list(swn.senti_synsets('awesome', 'a'))[0]\n",
    "print('Positive Polarity Score:', awesome.pos_score())\n",
    "print('Negative Polarity Score:', awesome.neg_score())\n",
    "print('Objective Score:', awesome.obj_score())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sentiment_sentiwordnet_lexicon(article,\n",
    "                                           verbose=False):\n",
    "\n",
    "    # tokenize and POS tag text tokens\n",
    "    tagged_text = [(token.text, token.tag_) for token in tn.nlp(article)]\n",
    "    pos_score = neg_score = token_count = obj_score = 0\n",
    "    # get wordnet synsets based on POS tags\n",
    "    # get sentiment scores if synsets are found\n",
    "    for word, tag in tagged_text:\n",
    "        ss_set = None\n",
    "        if 'NN' in tag and list(swn.senti_synsets(word, 'n')):\n",
    "            ss_set = list(swn.senti_synsets(word, 'n'))[0]\n",
    "        elif 'VB' in tag and list(swn.senti_synsets(word, 'v')):\n",
    "            ss_set = list(swn.senti_synsets(word, 'v'))[0]\n",
    "        elif 'JJ' in tag and list(swn.senti_synsets(word, 'a')):\n",
    "            ss_set = list(swn.senti_synsets(word, 'a'))[0]\n",
    "        elif 'RB' in tag and list(swn.senti_synsets(word, 'r')):\n",
    "            ss_set = list(swn.senti_synsets(word, 'r'))[0]\n",
    "        # if senti-synset is found        \n",
    "        if ss_set:\n",
    "            # add scores for all found synsets\n",
    "            pos_score += ss_set.pos_score()\n",
    "            neg_score += ss_set.neg_score()\n",
    "            obj_score += ss_set.obj_score()\n",
    "            token_count += 1\n",
    "    \n",
    "    # aggregate final scores\n",
    "    final_score = pos_score - neg_score\n",
    "    norm_final_score = round(float(final_score) / token_count, 2)\n",
    "    final_sentiment = 'positive' if norm_final_score >= 0 else 'negative'\n",
    "    if verbose:\n",
    "        norm_obj_score = round(float(obj_score) / token_count, 2)\n",
    "        norm_pos_score = round(float(pos_score) / token_count, 2)\n",
    "        norm_neg_score = round(float(neg_score) / token_count, 2)\n",
    "        # to display results in a nice table\n",
    "        sentiment_frame = pd.DataFrame([[final_sentiment, norm_obj_score, norm_pos_score, \n",
    "                                         norm_neg_score, norm_final_score]],\n",
    "                                       columns=pd.MultiIndex(levels=[['SENTIMENT STATS:'], \n",
    "                                                             ['Predicted Sentiment', 'Objectivity',\n",
    "                                                              'Positive', 'Negative', 'Overall']], \n",
    "                                                             labels=[[0,0,0,0,0],[0,1,2,3,4]]))\n",
    "        print(sentiment_frame)\n",
    "        \n",
    "    return final_sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict sentiment for sample articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "article:  alexandria, va: united states patent and trademark office has received an application no. 20170281686 for us patent, published on october 5, 2017, by stembiosys, inc. (texas), titled as \"bone marrow stromal cell derived extracellular matrix protein extract and uses thereof\"  for the registration of patent.\n",
      "\n",
      " stembiosys, inc. (texas) applies for us patent titled as \"bone marrow stromal cell derived extracellular matrix protein extract and uses thereof\"\n",
      "Actual Sentiment: neutral\n",
      "     SENTIMENT STATS:                                      \n",
      "  Predicted Sentiment Objectivity Positive Negative Overall\n",
      "0            negative        0.97     0.01     0.02   -0.01\n",
      "------------------------------------------------------------\n",
      "article: fashion and apparel, a $110-130 billion market, offers 30-40% margins but it is crowded with the likes of the flipkart-jabong-myntra combine, amazon and more than 800 other players such as limeroad and voonik jostling for space. snapdeal will spend $100 million to build this category, says bahl.\\x93to build any of these we could even look at acquiring capabilities,\\x93 says bahl. the acquisition in may 2016 of targetingmantra, a predictive marketing tech firm that helps make recommendations, might help here.\n",
      "Actual Sentiment: neutral\n",
      "     SENTIMENT STATS:                                      \n",
      "  Predicted Sentiment Objectivity Positive Negative Overall\n",
      "0            positive        0.94     0.03     0.03     0.0\n",
      "------------------------------------------------------------\n",
      "article: medallia, the sillicon valley based company that supplies tools for real time measuring of customers experience with corporations, has local operations since 2011. president cristian rapagna says most of its clients are large corporations that need to keep in touch with customers to assess the acceptance of products and services. the goal is to gather data to improve the customers experience, as fulfilled customers tend to increase expenditures, contrary to the ones that have had a poor experience. medallia is the sole company to offer these tools and services, while market feedback services are not considered competitors, the company, with 650 employees, collects information from social networks and the internet assessing customers satisfaction. the local branch also develop tools related to the business of its parent in the us.\n",
      "Actual Sentiment: neutral\n",
      "     SENTIMENT STATS:                                      \n",
      "  Predicted Sentiment Objectivity Positive Negative Overall\n",
      "0            positive         0.9     0.05     0.05     0.0\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for article, sentiment in zip(test_articles[sample_article_ids], test_sentiments[sample_article_ids]):\n",
    "    print('article:', article)\n",
    "    print('Actual Sentiment:', sentiment)\n",
    "    pred = analyze_sentiment_sentiwordnet_lexicon(article, verbose=True)    \n",
    "    print('-'*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict sentiment for test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_sentiments = [analyze_sentiment_sentiwordnet_lexicon(article, verbose=False) for article in norm_test_articles]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance metrics:\n",
      "------------------------------\n",
      "Accuracy: 0.0612\n",
      "Precision: 0.0037\n",
      "Recall: 0.0612\n",
      "F1 Score: 0.0071\n",
      "\n",
      "Model Classification report:\n",
      "------------------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   positive       0.06      1.00      0.12         5\n",
      "   negative       0.06      1.00      0.11         1\n",
      "\n",
      "avg / total       0.06      1.00      0.12         6\n",
      "\n",
      "\n",
      "Prediction Confusion Matrix:\n",
      "------------------------------\n",
      "                 Predicted:         \n",
      "                   positive negative\n",
      "Actual: positive          5        0\n",
      "        negative          0        1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tie-server/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/tie-server/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "meu.display_model_performance_metrics(true_labels=test_sentiments, predicted_labels=predicted_sentiments, \n",
    "                                  classes=['positive', 'negative'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis with VADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tie-server/anaconda3/lib/python3.6/site-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
      "  warnings.warn(\"The twython library has not been installed. \"\n"
     ]
    }
   ],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sentiment_vader_lexicon(article, \n",
    "                                    threshold=0.1,\n",
    "                                    verbose=False):\n",
    "    # pre-process text\n",
    "    article = tn.strip_html_tags(article)\n",
    "    article = tn.remove_accented_chars(article)\n",
    "    article = tn.expand_contractions(article)\n",
    "    \n",
    "    # analyze the sentiment for article\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    scores = analyzer.polarity_scores(article)\n",
    "    # get aggregate scores and final sentiment\n",
    "    agg_score = scores['compound']\n",
    "    final_sentiment = 'positive' if agg_score >= threshold\\\n",
    "                                   else 'negative'\n",
    "    if verbose:\n",
    "        # display detailed sentiment statistics\n",
    "        positive = str(round(scores['pos'], 2)*100)+'%'\n",
    "        final = round(agg_score, 2)\n",
    "        negative = str(round(scores['neg'], 2)*100)+'%'\n",
    "        neutral = str(round(scores['neu'], 2)*100)+'%'\n",
    "        sentiment_frame = pd.DataFrame([[final_sentiment, final, positive,\n",
    "                                        negative, neutral]],\n",
    "                                        columns=pd.MultiIndex(levels=[['SENTIMENT STATS:'], \n",
    "                                                                      ['Predicted Sentiment', 'Polarity Score',\n",
    "                                                                       'Positive', 'Negative', 'Neutral']], \n",
    "                                                              labels=[[0,0,0,0,0],[0,1,2,3,4]]))\n",
    "        print(sentiment_frame)\n",
    "    \n",
    "    return final_sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict sentiment for sample articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "article:  alexandria, va: united states patent and trademark office has received an application no. 20170281686 for us patent, published on october 5, 2017, by stembiosys, inc. (texas), titled as \"bone marrow stromal cell derived extracellular matrix protein extract and uses thereof\"  for the registration of patent.\n",
      "\n",
      " stembiosys, inc. (texas) applies for us patent titled as \"bone marrow stromal cell derived extracellular matrix protein extract and uses thereof\"\n",
      "Actual Sentiment: neutral\n",
      "     SENTIMENT STATS:                                         \n",
      "  Predicted Sentiment Polarity Score Positive Negative Neutral\n",
      "0            negative           0.15     4.0%     3.0%   93.0%\n",
      "------------------------------------------------------------\n",
      "article: fashion and apparel, a $110-130 billion market, offers 30-40% margins but it is crowded with the likes of the flipkart-jabong-myntra combine, amazon and more than 800 other players such as limeroad and voonik jostling for space. snapdeal will spend $100 million to build this category, says bahl.\\x93to build any of these we could even look at acquiring capabilities,\\x93 says bahl. the acquisition in may 2016 of targetingmantra, a predictive marketing tech firm that helps make recommendations, might help here.\n",
      "Actual Sentiment: neutral\n",
      "     SENTIMENT STATS:                                         \n",
      "  Predicted Sentiment Polarity Score Positive Negative Neutral\n",
      "0            positive           0.91    15.0%     0.0%   85.0%\n",
      "------------------------------------------------------------\n",
      "article: medallia, the sillicon valley based company that supplies tools for real time measuring of customers experience with corporations, has local operations since 2011. president cristian rapagna says most of its clients are large corporations that need to keep in touch with customers to assess the acceptance of products and services. the goal is to gather data to improve the customers experience, as fulfilled customers tend to increase expenditures, contrary to the ones that have had a poor experience. medallia is the sole company to offer these tools and services, while market feedback services are not considered competitors, the company, with 650 employees, collects information from social networks and the internet assessing customers satisfaction. the local branch also develop tools related to the business of its parent in the us.\n",
      "Actual Sentiment: neutral\n",
      "     SENTIMENT STATS:                                         \n",
      "  Predicted Sentiment Polarity Score Positive Negative Neutral\n",
      "0            positive           0.87    10.0%     2.0%   88.0%\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for article, sentiment in zip(test_articles[sample_article_ids], test_sentiments[sample_article_ids]):\n",
    "    print('article:', article)\n",
    "    print('Actual Sentiment:', sentiment)\n",
    "    pred = analyze_sentiment_vader_lexicon(article, threshold=0.4, verbose=True)    \n",
    "    print('-'*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict sentiment for test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_sentiments = [analyze_sentiment_vader_lexicon(article, threshold=0.4, verbose=False) for article in test_articles]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance metrics:\n",
      "------------------------------\n",
      "Accuracy: 0.0612\n",
      "Precision: 0.0043\n",
      "Recall: 0.0612\n",
      "F1 Score: 0.0081\n",
      "\n",
      "Model Classification report:\n",
      "------------------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   positive       0.08      1.00      0.15         5\n",
      "   negative       0.03      1.00      0.06         1\n",
      "\n",
      "avg / total       0.07      1.00      0.13         6\n",
      "\n",
      "\n",
      "Prediction Confusion Matrix:\n",
      "------------------------------\n",
      "                 Predicted:         \n",
      "                   positive negative\n",
      "Actual: positive          5        0\n",
      "        negative          0        1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tie-server/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/tie-server/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "meu.display_model_performance_metrics(true_labels=test_sentiments, predicted_labels=predicted_sentiments, \n",
    "                                  classes=['positive', 'negative'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
